# LLM API Keys (use one or more)
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
GOOGLE_API_KEY=your_google_api_key_here

# LLM Configuration
CLASSIFICATION_MODEL=gpt-4o-search-preview
EMAIL_GENERATION_MODEL=gpt-3.5-turbo

# Processing Configuration
# For gpt-4o-search-preview: 100 RPM limit, 6000 TPM limit
# Conservative settings to avoid rate limits (retry logic can amplify load)
# Known competitors are pre-validated without API calls, reducing total requests
# Expected time for 200 speakers: ~20-30 minutes
MAX_CONCURRENT_REQUESTS=2
REQUEST_DELAY_SECONDS=2

# Debug Configuration
# DEBUG=false: Continue processing on errors, return default classification (Production)
# DEBUG=true: Exit immediately on any error (Development/Testing)
# Note: Rate limit errors always exit immediately regardless of DEBUG setting
DEBUG=false
